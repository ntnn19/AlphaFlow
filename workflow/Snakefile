
import os
from scripts import create_tasks_from_dataframe
INPUT_DF = config["input_csv"]
OUTPUT_DIR = config["output_dir"]
MODE = config.get("mode","defualt")
MSA_OPTION = config.get("msa_option","auto")

if MSA_OPTION == "auto":
    MSA_OPTION_1 = "auto_template_free"
    MSA_OPTION_2 = "auto_template_based"
    TASKS_PATHS_AND_JOB_NAMES_1 = create_tasks_from_dataframe.create_tasks_from_dataframe([INPUT_DF,OUTPUT_DIR+"/PREPROCESSING","--mode",MODE,"--msa-option",MSA_OPTION_1],standalone_mode=False)
    TASKS_PATHS_AND_JOB_NAMES_2 = create_tasks_from_dataframe.create_tasks_from_dataframe([INPUT_DF,OUTPUT_DIR+"/PREPROCESSING","--mode",MODE,"--msa-option",MSA_OPTION_2],standalone_mode=False)
    TASKS_PATHS = TASKS_PATHS_AND_JOB_NAMES_1[0] + TASKS_PATHS_AND_JOB_NAMES_2[0]
    JOB_NAMES = TASKS_PATHS_AND_JOB_NAMES_1[1] + TASKS_PATHS_AND_JOB_NAMES_2[1]

else:
    TASKS_PATHS_AND_JOB_NAMES = create_tasks_from_dataframe.create_tasks_from_dataframe([INPUT_DF,
                                                                                           OUTPUT_DIR + "/PREPROCESSING",
                                                                                           "--mode", MODE,],standalone_mode=False)
    TASKS_PATHS = TASKS_PATHS_AND_JOB_NAMES[0]
    JOB_NAMES = TASKS_PATHS_AND_JOB_NAMES[1]

rule all:
    input:
        expand(os.path.join(OUTPUT_DIR,"AF3_INFERENCE","{i}/{i}/{i}_model.cif"),i=JOB_NAMES),
        expand(os.path.join(OUTPUT_DIR,"AF3_DATA","{i}/{i}_data.json"),i=JOB_NAMES),


rule AF3_DATA:
    input:
        os.path.join(OUTPUT_DIR,"PREPROCESSING","{i}.json")
    output:
        data_pipeline_msa = os.path.join(OUTPUT_DIR,"AF3_DATA","{i}/{i}_data.json"),
    resources:
        slurm_partition="vds",
        nodes=1,
        runtime=10000,
        cpus_per_task=16,
    container:
        config["af3_container"]
    shell:
        """
        python /app/alphafold/run_alphafold.py --json_path=/root/af_output/preprocessing/{wildcards.i}.json \
        --model_dir=/root/models \
        --output_dir=/root/af_output/AF3_DATA \
        --db_dir=/root/public_databases \
        --run_data_pipeline=true \
        --run_inference=false
        """


rule AF3_INFERENCE:
    input:
        data_pipeline_msa= os.path.join(OUTPUT_DIR,"AF3_DATA","{i}/{i}_data.json"),
    output:
        os.path.join(OUTPUT_DIR,"AF3_INFERENCE","{i}/{i}/{i}_model.cif"),
    resources:
        slurm_extra="'--gpus-per-node=1'",
        nodes=1,
        runtime=10000,
        memory="256G",
    container:
        config["af3_container"]
    shell:
        """
        python /app/alphafold/run_alphafold.py --json_path=/root/af_output/AF3_DATA/{wildcards.i}/{wildcards.i}_data.json \
        --model_dir=/root/models \
        --output_dir=/root/af_output/AF3_INFERENCE/{wildcards.i} \
        --db_dir=/root/public_databases \
        --run_data_pipeline=false \
        --run_inference=true
        """
